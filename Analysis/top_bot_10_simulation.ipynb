{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import math\n",
    "\n",
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc134e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is connected\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.config.list_physical_devices('CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For importing processed data\n",
    "# processed_data_path = 'file_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8149178",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_factors = ['cshtrd', 'prccd', 'prchd', 'prcld', 'prcod', 'dol_vol', 'Mom_2day', 'Mom_3day', 'Mom_5day',\n",
    "                 'MA_10day', 'MA_50day', 'open/MA10', 'open/MA50', 'STD_10day', 'H-L', 'RSI', 'MACD', 'MACD_Signal_Line']\n",
    "\n",
    "TA_factors = [# Momentum indicators\n",
    "              'momentum_stoch_rsi', 'momentum_stoch', 'momentum_ao', 'momentum_pvo', 'momentum_kama', 'momentum_wr',\n",
    "              # Volume indicators\n",
    "              'volume_adi', 'volume_em', 'volume_fi', 'volume_cmf', 'volume_vpt',\n",
    "              # Volatility indicators\n",
    "              'volatility_atr', 'volatility_bbh', 'volatility_dcw', 'volatility_ui',\n",
    "              # Trend indicators\n",
    "              'trend_adx', 'trend_aroon_up', 'trend_aroon_down', 'trend_ichimoku_a',\n",
    "              # Other indicators\n",
    "              'others_dr'\n",
    "]\n",
    "\n",
    "# Remove factors that have low variance\n",
    "basic_factors.remove('dol_vol')\n",
    "\n",
    "# Remove factors that have high correlation with the prcod (and prcod since it shouldn't affect the return)\n",
    "basic_factors.remove('prccd')\n",
    "basic_factors.remove('prcld')\n",
    "basic_factors.remove('prchd')\n",
    "basic_factors.remove('prcod')\n",
    "basic_factors.remove('MA_10day')\n",
    "TA_factors.remove('trend_ichimoku_a')\n",
    "TA_factors.remove('volatility_bbh')\n",
    "TA_factors.remove('momentum_kama')\n",
    "\n",
    "# Remove factors that have high correlation with momentum_stoch\n",
    "TA_factors.remove('momentum_wr')\n",
    "\n",
    "factors = basic_factors + TA_factors\n",
    "print(f'There are {len(basic_factors)} basic factors')\n",
    "print(f'There are {len(TA_factors)} TA factors')\n",
    "print(f'There are {len(factors)} factors')\n",
    "\n",
    "data = pd.read_csv(processed_data_path)\n",
    "all_days = list(data['datadate'].unique())\n",
    "num_of_tokens = data.sector.nunique()\n",
    "num_to_tic_dict, tic_to_num_dict = num_tic_dicts(data)\n",
    "\n",
    "data = remove_dead_stocks(data)\n",
    "\n",
    "data = assign_class_labels(data, 'fixed_thres')\n",
    "data = data[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days = list(data['datadate'].unique())\n",
    "num_of_ts = len(all_days)\n",
    "batch_size = 4096 # Only for model.predict()\n",
    "print(f'There are {num_of_ts} days in the dataset')\n",
    "\n",
    "tickers = list(data.tic.unique())\n",
    "nt = len(tickers)\n",
    "print(f'There are {nt} tickers')\n",
    "assert len(tickers) * num_of_ts == data.shape[0]\n",
    "\n",
    "seq_length = 20 # Length of time-series\n",
    "train_length = 200 # Length of training data\n",
    "ftd = train_length # First train day\n",
    "ltd = ftd+train_length-1 # Last train day\n",
    "num_stocks = 10 # Choose the top {num_stocks} each day\n",
    "num_of_models = 3\n",
    "\n",
    "num_iters = math.floor((num_of_ts - 2*train_length) / seq_length)\n",
    "print(f'There are {num_iters} iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "# Add the path where all models are saved\n",
    "# model_folder = 'file_path'\n",
    "\n",
    "return_dict = {}\n",
    "total_dict = {}\n",
    "total_asset_dict = {}\n",
    "position_dict_all = {}\n",
    "for i in range(num_of_models):\n",
    "    total_dict[f'model_{i}_top'] = 1\n",
    "    total_dict[f'model_{i}_bot'] = 1\n",
    "    total_asset_dict[f'model_{i}_top'] = [1]\n",
    "    total_asset_dict[f'model_{i}_bot'] = [1]\n",
    "    position_dict_all[f'model_{i}_top'] = {}\n",
    "    position_dict_all[f'model_{i}_bot'] = {}\n",
    "total_dict['ensemble_equal_top'] = 1\n",
    "total_dict['ensemble_equal_bot'] = 1\n",
    "total_asset_dict['ensemble_equal_top'] = [1]\n",
    "total_asset_dict['ensemble_equal_bot'] = [1]\n",
    "position_dict_all['ensemble_equal_top'] = {}\n",
    "position_dict_all['ensemble_equal_bot'] = {}\n",
    "total_dict['ensemble_weighted_top'] = 1\n",
    "total_dict['ensemble_weighted_bot'] = 1\n",
    "total_asset_dict['ensemble_weighted_top'] = [1]\n",
    "total_asset_dict['ensemble_weighted_bot'] = [1]\n",
    "position_dict_all['ensemble_weighted_top'] = {}\n",
    "position_dict_all['ensemble_weighted_bot'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c1f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num_iter in range(2):\n",
    "\n",
    "    print(f'Iteration {num_iter+1} of {num_iters}')\n",
    "    if num_iter != 0:\n",
    "        first_run = False\n",
    "    else:\n",
    "        first_run = True\n",
    "\n",
    "    ftd = train_length + num_iter * seq_length\n",
    "    ltd = ftd + train_length - 1\n",
    "\n",
    "    # Get data_train, data_test etc\n",
    "    data_train, x_train, y_train, data_test, x_test, y_test, ret_d_train, ret_d_test, sector_train, sector_test = prep_train_test_data(data, seq_length, ftd, ltd, all_days)\n",
    "\n",
    "    # Import/train/retrain (if needed) the models for the test period\n",
    "    for i in range(num_of_models):\n",
    "\n",
    "        # Import models\n",
    "        model_path = model_folder + f\"model_{i}_{all_days[ftd]}_{all_days[ltd]}.keras\"\n",
    "        model_dict[i] = keras.models.load_model(model_path)\n",
    "\n",
    "    total_asset_dict, total_dict, position_dict_all, return_dict = simulate_top_bot(ftd, ltd, total_dict, first_run, num_stocks, total_asset_dict, position_dict_all, return_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5f765",
   "metadata": {},
   "source": [
    "# SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(processed_data_path, usecols=['datadate', 'TBill1y'])\n",
    "data = data.drop_duplicates(subset=['datadate'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_simul_day = \"2024-12-03\"\n",
    "rfr = list(data[data['datadate'] <= last_simul_day]['TBill1y'])\n",
    "rfr = rfr[-67*20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in total_asset_dict.items():\n",
    "    SR = calculate_SR(item, rfr)\n",
    "    print(f'SR for model {key} is {SR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keys = []\n",
    "bot_keys = []\n",
    "for model in ['model_0_', 'model_1_', 'model_2_', 'ensemble_equal_', 'ensemble_weighted_']:\n",
    "    top_keys.append(model + 'top')\n",
    "    bot_keys.append(model + 'bot')\n",
    "calculate_H_L_SR(total_asset_dict, top_keys, bot_keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
