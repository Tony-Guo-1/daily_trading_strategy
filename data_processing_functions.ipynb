{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48075c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tic(data, tickers, num_of_ts, factors):\n",
    "    '''\n",
    "    Input: data, tickers, num_of_ts, factors\n",
    "    1. Removes entries without price/volume data\n",
    "    2. Removes entries without enough time steps\n",
    "    Output: data, tickers\n",
    "    '''\n",
    "    # Remove entries without key factors such as trading volume, open/close prices\n",
    "    tic_rm_count = 0\n",
    "    for f in ['cshoc', 'cshtrd']:\n",
    "        data[f] = data.groupby('tic')[f].ffill()\n",
    "        data[f] = data.groupby('tic')[f].bfill()\n",
    "    for f in ['prccd', 'prchd', 'prcld', 'prcod']:\n",
    "        tic_to_remove = list(data[data[f].isna()].tic.unique())\n",
    "        tic_rm_count += len(tic_to_remove)\n",
    "        print(f'Removed {tic_to_remove} for missing {f}')\n",
    "        data = data[~data['tic'].isin(tic_to_remove)]\n",
    "    print(f'There are {tic_rm_count} unique tickers to remove due to missing values')\n",
    "    \n",
    "    # Remove entries where there are not enough number of time stamps\n",
    "    databytic_count = data.groupby('tic').count()\n",
    "    incomplete_tics = databytic_count.loc[databytic_count['datadate']<num_of_ts].index.tolist()\n",
    "    print(f'Removed {incomplete_tics}')\n",
    "    data = data[~data['tic'].isin(incomplete_tics)]\n",
    "    tickers = data['tic'].unique()\n",
    "    print(f'There are {len(incomplete_tics)} unique tickers to remove due to insufficient timestamps')\n",
    "    print('There are ' + str(len(tickers)) + ' tickers')\n",
    "\n",
    "    print(f'Confirm there are no more columns with missing data {data.columns[data.isnull().sum() != 0]}')\n",
    "    \n",
    "    # Sort data by tickers and date\n",
    "    data = data.sort_values(by=['tic','datadate'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return data, tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_dollar_vol(data, tickers, dol_vol_thres = 10000000):\n",
    "    '''\n",
    "    Input: data, tickers, dol_vol_thres\n",
    "    1. Remove tickers whose dollar volume is less than dol_vol_thres (default 10M)\n",
    "    Output: data, tickers\n",
    "    '''\n",
    "    data['dol_vol'] = data['cshtrd'] * data['prcod']\n",
    "    dolvol_means = data.groupby('tic')['dol_vol'].mean()\n",
    "    dolvol_remove = dolvol_means[dolvol_means < dol_vol_thres].index\n",
    "    print(f'Removed {len(dolvol_remove)} tickers due to low dollar volume')\n",
    "    data = data[~data['tic'].isin(dolvol_remove)]\n",
    "    tickers = data['tic'].unique()\n",
    "    print('There are ' + str(len(tickers)) + ' tickers')\n",
    "    return data, tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2002b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ret(data, TBill_file_path):\n",
    "    '''\n",
    "    Input: data, tickers\n",
    "    1. Create ret_d colume, e.g. 2024-2-2's ret_d is the percentage return of buying at 2024-2-3 market open and \n",
    "    selling at 2024-2-4 market open\n",
    "    2. Fill last two days of missing return as 0\n",
    "    3. Compute the excess return column by subtracting the risk-free rate\n",
    "    Output: data, tickers\n",
    "    '''\n",
    "    # Add additional column 'ret_d'\n",
    "    data['ret_d'] = data.groupby('tic')['prcod'].pct_change()\n",
    "    data['ret_d'] = data.groupby('tic')['ret_d'].shift(-2)\n",
    "    \n",
    "    # Currently the last day has no ret_d since it's the test date. Fill it with 0\n",
    "    data = data.fillna(0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Excess return\n",
    "    TBill3m = pd.read_csv(TBill_file_path)\n",
    "    TBill3m['Date'] = pd.to_datetime(TBill3m['Date'], format=\"%m/%d/%y\")\n",
    "    date_TBill_dict = TBill3m[['Date', ' Open']].set_index('Date')[' Open'].to_dict()\n",
    "    data['TBill3m'] = data['datadate'].map(date_TBill_dict)\n",
    "    data['TBill3m'] = data['TBill3m'].fillna(0)\n",
    "    # Convert to daily rate\n",
    "    data['TBill3m'] = data['TBill3m'].apply(lambda x: np.power(1 + x/100, 1/252) - 1)\n",
    "    data['excess_ret_d'] = data['ret_d'] - data['TBill3m']\n",
    "    \n",
    "    # Relative return to equal-weighted market returns\n",
    "    data['market_ret'] = data['datadate'].map(data.groupby('datadate')['ret_d'].mean())\n",
    "    data['rel_ret_d'] = data['ret_d'] - data['market_ret']\n",
    "    data = data.drop(columns=['market_ret'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dead_stocks(data, price_thres = 0.1):\n",
    "    '''\n",
    "    This goes after compute_ret to change those dead stock's return and their rank to 0\n",
    "    '''\n",
    "    df_low_price = data[data['prcod'] <= price_thres]\n",
    "    tic_low_price = list(df_low_price.tic.unique())\n",
    "    for tic in tic_low_price:\n",
    "        date_low_price = df_low_price[df_low_price['tic']==tic].datadate.values[0]\n",
    "        data.loc[(data['tic'] == tic) & (data['datadate'] >= date_low_price), ['ret_d', 'excess_ret_d', 'rel_ret_d', 'rank']] = 0\n",
    "        print(f'{tic} is dead after {date_low_price}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_label(x):\n",
    "#     if x >= 0.05:\n",
    "#         return 2\n",
    "#     elif 0.01 <= x < 0.05:\n",
    "#         return 1\n",
    "#     elif -0.01 <= x < 0.01:\n",
    "#         return 0\n",
    "#     elif -0.05 <= x < -0.01:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3004111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_movement_label(x):\n",
    "#     if abs(x) <= 0.01:\n",
    "#         return -2\n",
    "#     elif abs(x) <= 0.03:\n",
    "#         return -1\n",
    "#     elif abs(x) <= 0.05:\n",
    "#         return 0\n",
    "#     elif abs(x) <= 0.07:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff253b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_direction_label(x):\n",
    "#     if x < -0.01:\n",
    "#         return -1\n",
    "#     elif abs(x) < 0.01:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class_label(x):\n",
    "    if x <= -0.03:\n",
    "        return -2\n",
    "    elif x <= -0.01:\n",
    "        return -1\n",
    "    elif x <= 0.01:\n",
    "        return 0\n",
    "    elif x < 0.03:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio(data, quantiles = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]):\n",
    "    '''\n",
    "    Input: data, quantiles (default: equal split into 5 classes)\n",
    "    Compute the daily rank of every stock\n",
    "    Output: data\n",
    "    '''\n",
    "    # 1. Evenly bin everything into 5 labels\n",
    "    # data['DistinctRank'] = data.groupby('datadate')['ret_d'].rank('first') # Lowest first\n",
    "    # data['rank'] = data.groupby('datadate')['DistinctRank'].transform(lambda x: pd.qcut(x, quantiles, labels=[-2, -1, 0, 1, 2]))\n",
    "\n",
    "    # 2. Manually set the bin threshold to be \\pm 0.01 and \\pm 0.05\n",
    "    # data['rank'] = data['ret_d'].apply(assign_label)\n",
    "\n",
    "    # 3. Have the model predict the size of movement of the stock (to be later combined with another expert on the direction (up/down/hold))\n",
    "    # data['rank'] = data['ret_d'].apply(assign_movement_label)\n",
    "    # data['direction'] = data['ret_d'].apply(assign_direction_label)\n",
    "\n",
    "    data['rank'] = data['ret_d'].apply(assign_class_label)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddebb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data, cs_factors):\n",
    "    '''\n",
    "    Input: data\n",
    "    1. Standardize data either cross-sectionally or ticker-wise\n",
    "    2. Change outliers (3 STD away from mean) to plus-minus 3\n",
    "    '''\n",
    "    # Cross-sectional standardization\n",
    "    data_cs = data[cs_factors].groupby('datadate').transform(lambda x: (x - x.mean()) / x.std())\n",
    "    # winsorize further\n",
    "    # data_cs[data_cs > 3] = 3\n",
    "    # data_cs[data_cs < -3] = -3\n",
    "    \n",
    "    cs_factors.remove('datadate')\n",
    "    data.loc[:, cs_factors] = data_cs\n",
    "\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    print(f'Confirm that standardization did not create NaNs: {data.columns[data.isnull().sum() != 0]}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_split(data, tickers, factors):\n",
    "    '''\n",
    "    Adjust numeric factors for stock splitting, using the adjustment factor\n",
    "    '''\n",
    "    # Divide columns in factors by ajexdi\n",
    "    data[factors] = data[factors].div(data['ajexdi'].values, axis=0)\n",
    "    \n",
    "    # After adjusting for stock splitting and possibly selecting stocks based on exchange we can drop these columns\n",
    "    data = data.drop(columns=['ajexdi', 'exchg'])\n",
    "    \n",
    "    return data, tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a71056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sic_column(data, filename):\n",
    "\n",
    "    sic_data = pd.read_csv(filename)\n",
    "    sic_data = sic_data[~sic_data['sic'].isnull()]\n",
    "    data = data.merge(sic_data, on='tic', how='left')\n",
    "    \n",
    "    # Remove data that have no SIC code (Those were leveraged ETFs)\n",
    "    data = data[~data.sic.isnull()]\n",
    "    num_of_tokens = data.sic.nunique()\n",
    "    \n",
    "    # Renumber the sics from 0 to num_of_tokens-1\n",
    "    all_sics = list(data.sic.unique())\n",
    "    renumber_sics = {}\n",
    "    for i in range(len(all_sics)):\n",
    "        renumber_sics[all_sics[i]] = i\n",
    "    data['sic'] = data['sic'].replace(renumber_sics)\n",
    "    \n",
    "    return data, num_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1149c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tic_dicts(data):\n",
    "    all_tickers = list(data['tic'].unique())\n",
    "    all_tickers.sort()\n",
    "    l = len(all_tickers)\n",
    "    \n",
    "    num_to_tic_dict = {}\n",
    "    for i in range(l):\n",
    "        num_to_tic_dict[i] = all_tickers[i]\n",
    "    \n",
    "    tic_to_num_dict = {}\n",
    "    for key, value in num_to_tic_dict.items():\n",
    "        tic_to_num_dict[value] = key\n",
    "    \n",
    "    return num_to_tic_dict, tic_to_num_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
