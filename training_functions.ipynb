{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_test_data(data, seq_length, ftd, ltd, all_days):\n",
    "    '''\n",
    "    Input: data, seq_length (length of time-series to in input), ftd: first training date (index), ltd: last training date (index)\n",
    "    Output:\n",
    "    data_train, x_train with shape (batchsize, seq_length, channels), y_train with shape (batchsize, ), data_test, x_test, y_test\n",
    "    ret_d_train, ret_d_test: daily percentage returns \n",
    "    '''\n",
    "\n",
    "    num_st_days = 200 # Number of days used for standardization\n",
    "    if ftd < num_st_days:\n",
    "        print('not enough standardization days')\n",
    "    \n",
    "    first_st_day = all_days[ftd-num_st_days]\n",
    "    last_st_day = all_days[ftd-1]\n",
    "    first_train_day = all_days[ftd]\n",
    "    last_train_day = all_days[ltd]\n",
    "    first_test_day = all_days[ltd-seq_length+2]\n",
    "    last_test_day = all_days[ltd+seq_length]\n",
    "    print(f'Standardization data are from {first_st_day} to {last_st_day}')\n",
    "    print(f'Training data are from {first_train_day} to {last_train_day}')\n",
    "    print(f'Testing data are from {first_test_day} to {last_test_day}')\n",
    "    data_st = data[(data['datadate'] >= first_st_day) & (data['datadate'] <= last_st_day)].reset_index(drop=True)\n",
    "    data_train = data[(data['datadate'] >= first_train_day) & (data['datadate'] <= last_train_day)].reset_index(drop=True)\n",
    "    data_test = data[(data['datadate'] >= first_test_day) & (data['datadate'] <= last_test_day)].reset_index(drop=True)\n",
    "    \n",
    "    # Standardize here \n",
    "    # 1. for both train and test, use the X days before the first train day\n",
    "    df_mean = data_st[factors + ['tic']].groupby('tic').mean().reset_index()\n",
    "    df_std = data_st[factors + ['tic']].groupby('tic').std().reset_index()\n",
    "    df_train = pd.merge(data_train, df_mean, how='left', on=['tic'], suffixes=('', '_MEAN'))\n",
    "    df_test = pd.merge(data_test, df_mean, how='left', on=['tic'], suffixes=('', '_MEAN'))\n",
    "    # 2. Use X days before the first train day and all stocks in the same sector\n",
    "    # df_mean = data_st[factors + ['sector']].groupby('sector').mean().reset_index()\n",
    "    # df_std = data_st[factors + ['sector']].groupby('sector').std().reset_index()\n",
    "    # df_train = pd.merge(data_train, df_mean, how='left', on=['sector'], suffixes=('', '_MEAN'))\n",
    "    # df_test = pd.merge(data_test, df_mean, how='left', on=['sector'], suffixes=('', '_MEAN'))\n",
    "    for factor in factors:\n",
    "        df_train[factor] = df_train[factor] - df_train[f'{factor}_MEAN']\n",
    "        df_test[factor] = df_test[factor] - df_test[f'{factor}_MEAN']\n",
    "    df_train = df_train[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "    df_test = df_test[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "    # 1. tic level standardization\n",
    "    df_train = pd.merge(df_train, df_std, how='left', on=['tic'], suffixes=('', '_STD'))\n",
    "    df_test = pd.merge(df_test, df_std, how='left', on=['tic'], suffixes=('', '_STD'))\n",
    "    # 2. sector level standardization\n",
    "    # df_train = pd.merge(df_train, df_std, how='left', on=['sector'], suffixes=('', '_STD'))\n",
    "    # df_test = pd.merge(df_test, df_std, how='left', on=['sector'], suffixes=('', '_STD'))\n",
    "    for factor in factors:\n",
    "        df_train[factor] = df_train[factor] / df_train[f'{factor}_STD']\n",
    "        df_test[factor] = df_test[factor] / df_test[f'{factor}_STD']\n",
    "    data_train = df_train[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "    data_test = df_test[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "\n",
    "    # Winsorize here\n",
    "    # df_train[factors] = df_train[factors].clip(lower=-10, upper=10)\n",
    "    # df_test[factors] = df_test[factors].clip(lower=-10, upper=10)\n",
    "\n",
    "    # Fill NA\n",
    "    for factor in factors:\n",
    "        data_train.loc[:, factor] = data_train[factor].fillna(0)\n",
    "        data_test.loc[:, factor] = data_test[factor].fillna(0)\n",
    "\n",
    "    # Compute how many training data we will have\n",
    "    all_train_days = list(data_train.datadate.unique())\n",
    "    all_test_days = list(data_test.datadate.unique())\n",
    "    num_train_days = len(all_train_days)\n",
    "    num_test_days = len(all_test_days)\n",
    "    num_train_data = (num_train_days - seq_length + 1) * nt\n",
    "    num_test_data = (num_test_days - seq_length + 1) * nt\n",
    "        \n",
    "    # Create training data\n",
    "    x_train = np.zeros((num_train_data, len(factors), seq_length))\n",
    "    y_train = np.zeros((num_train_data, ))\n",
    "    ret_d_train = np.zeros((num_train_data, ))\n",
    "    sector_train = np.zeros((num_train_data, ))\n",
    "    for i in range(num_train_days - seq_length + 1):\n",
    "        train_days = all_train_days[i : seq_length + i]\n",
    "        data_temp = data_train[data_train['datadate'].isin(train_days)]\n",
    "        # Convert dataframe data to three dimensional training data (ticker, factor, time-series data)\n",
    "        pivot_data = data_temp[factors+['datadate', 'tic']].pivot_table(index='tic', columns='datadate')\n",
    "        x_train[i*nt:(i+1)*nt, :, :] = pivot_data.values.reshape(nt, len(factors), seq_length)\n",
    "        y_train[i*nt:(i+1)*nt] = data_train[data_train['datadate'] == train_days[-1]]['rank'].values.reshape(nt, )\n",
    "        ret_d_train[i*nt:(i+1)*nt] = data_train[data_train['datadate'] == train_days[-1]]['ret_d'].values.reshape(nt, )\n",
    "        # Get categorical input sector\n",
    "        sector_train[i*nt:(i+1)*nt] = data_train[data_train['datadate'] == train_days[-1]]['sector'].values.reshape(nt, )\n",
    "\n",
    "    # Create testing data\n",
    "    x_test = np.zeros((num_test_data, len(factors), seq_length))\n",
    "    y_test = np.zeros((num_test_data, ))\n",
    "    ret_d_test = np.zeros((num_test_data, ))\n",
    "    sector_test = np.zeros((num_test_data, ))\n",
    "    for i in range(num_test_days - seq_length + 1):\n",
    "        test_days = all_test_days[i : seq_length + i]\n",
    "        data_temp = data_test[data_test['datadate'].isin(test_days)]\n",
    "        pivot_data = data_temp[factors+['datadate', 'tic']].pivot_table(index='tic', columns='datadate')\n",
    "        x_test[i*nt:(i+1)*nt, :, :] = pivot_data.values.reshape(nt, len(factors), seq_length)\n",
    "        y_test[i*nt:(i+1)*nt] = data_test[data_test['datadate'] == test_days[-1]]['rank'].values.reshape(nt, )\n",
    "        ret_d_test[i*nt:(i+1)*nt] = data_test[data_test['datadate'] == test_days[-1]]['ret_d'].values.reshape(nt, )\n",
    "        # Get categorical input sector\n",
    "        sector_test[i*nt:(i+1)*nt] = data_test[data_test['datadate'] == test_days[-1]]['sector'].values.reshape(nt, )\n",
    "    \n",
    "    # Reshape train/test data so that it is channels_last\n",
    "    x_train = np.transpose(x_train, (0, 2, 1))\n",
    "    x_test = np.transpose(x_test, (0, 2, 1))\n",
    "    \n",
    "    # Let the label start with 0 to align with sparse cross-entropy\n",
    "    y_train[:] = y_train[:] + 2\n",
    "    y_test[:] = y_test[:] + 2\n",
    "    \n",
    "    print(f'Training data have shape {x_train.shape}, {y_train.shape}')\n",
    "    print(f'Testing data have shape {x_test.shape}, {y_test.shape}')\n",
    "    \n",
    "    return data_train, x_train, y_train, data_test, x_test, y_test, ret_d_train, ret_d_test, sector_train, sector_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0fbc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_test_data_regression(data, seq_length, ftd, ltd, all_days, factors):\n",
    "    '''\n",
    "    Processing techniques should be the same as the one above; remember to change them at the same time\n",
    "    '''\n",
    "\n",
    "    num_st_days = 200 # Number of days used for standardization\n",
    "    if ftd < num_st_days:\n",
    "        print('not enough standardization days')\n",
    "    \n",
    "    first_st_day = all_days[ftd-num_st_days]\n",
    "    last_st_day = all_days[ftd-1]\n",
    "    first_train_day = all_days[ftd]\n",
    "    last_train_day = all_days[ltd]\n",
    "    first_test_day = all_days[ltd-seq_length+2]\n",
    "    last_test_day = all_days[ltd+seq_length]\n",
    "    print(f'Standardization data are from {first_st_day} to {last_st_day}')\n",
    "    print(f'Training data are from {first_train_day} to {last_train_day}')\n",
    "    print(f'Testing data are from {first_test_day} to {last_test_day}')\n",
    "    data_st = data[(data['datadate'] >= first_st_day) & (data['datadate'] <= last_st_day)].reset_index(drop=True)\n",
    "    data_train = data[(data['datadate'] >= first_train_day) & (data['datadate'] <= last_train_day)].reset_index(drop=True)\n",
    "    data_test = data[(data['datadate'] >= first_test_day) & (data['datadate'] <= last_test_day)].reset_index(drop=True)\n",
    "    \n",
    "    # Standardize here \n",
    "    df_mean = data_st[factors + ['tic']].groupby('tic').mean().reset_index()\n",
    "    df_std = data_st[factors + ['tic']].groupby('tic').std().reset_index()\n",
    "    df_train = pd.merge(data_train, df_mean, how='left', on=['tic'], suffixes=('', '_MEAN'))\n",
    "    df_test = pd.merge(data_test, df_mean, how='left', on=['tic'], suffixes=('', '_MEAN'))\n",
    "    for factor in factors:\n",
    "        df_train[factor] = df_train[factor] - df_train[f'{factor}_MEAN']\n",
    "        df_test[factor] = df_test[factor] - df_test[f'{factor}_MEAN']\n",
    "    df_train = df_train[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "    df_test = df_test[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "    # tic level standardization\n",
    "    df_train = pd.merge(df_train, df_std, how='left', on=['tic'], suffixes=('', '_STD'))\n",
    "    df_test = pd.merge(df_test, df_std, how='left', on=['tic'], suffixes=('', '_STD'))\n",
    "    for factor in factors:\n",
    "        df_train[factor] = df_train[factor] / df_train[f'{factor}_STD']\n",
    "        df_test[factor] = df_test[factor] / df_test[f'{factor}_STD']\n",
    "    data_train = df_train[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "    data_test = df_test[['datadate', 'tic'] + factors + ['ret_d', 'TBill1y', 'rel_ret_d', 'rank', 'sector']]\n",
    "\n",
    "    # Fill NA\n",
    "    for factor in factors:\n",
    "        data_train.loc[:, factor] = data_train[factor].fillna(0)\n",
    "        data_test.loc[:, factor] = data_test[factor].fillna(0)\n",
    "    \n",
    "    y_train = np.array(data_train['ret_d'])\n",
    "    y_test = np.array(data_test['ret_d'])\n",
    "\n",
    "    return data_train, y_train, data_test, y_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
